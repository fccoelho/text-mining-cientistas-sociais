{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo um Classificador de Textos\n",
    "Uma das aplicações mais comuns em mineração de textos é a classificações de documentos em categorias pré-definidas, sejam elas autorais, temáticas, temporais ou outras. \n",
    "\n",
    "Neste capítulo iremos explorar os passos necessários para o desenvolvimento de um classificador de documentos utilizando as análises feitas sobre o corpus do DHBB nos capítulos anteriores.\n",
    "\n",
    "Para esta tarefa utilizaremos modelos de machine learning clássicos disponibilizados na biblioteca [Scikit-Learn](https://scikit-learn.org/). Começaremos então importando algumas funcionalidades a partir do Scikit-Learn. Os demais imports já foram utilizados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:11:52.781057Z",
     "start_time": "2020-11-30T18:11:52.776773Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 13:36:54.225423: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-26 13:36:54.878853: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-26 13:36:56.334327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-26 13:36:56.334583: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-26 13:36:56.334615: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-26 13:36:59.404132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-26 13:36:59.404581: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-26 13:36:59.404726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-26 13:36:59.404828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-26 13:36:59.405140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-26 13:36:59.405154: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gensim.models import Word2Vec, word2vec\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from string import punctuation\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o corpus\n",
    "Vamos utilizar o corpus do DHBB conforme armazenado na biblioteca SQLite anteriormente. Abaixo iremos desenvolver um iterador sobre o corpus que fará um preprocessamento básico dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:33:38.508266Z",
     "start_time": "2020-11-30T17:33:35.735062Z"
    }
   },
   "outputs": [],
   "source": [
    "eng = create_engine(\"sqlite:///minha_tabela.sqlite\")\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "class DHBBCorpus:\n",
    "    def __init__(self, ndocs=10000, process=True):\n",
    "        self.ndocs = min(7687,ndocs)\n",
    "        self.counter = 1\n",
    "    def __iter__(self):\n",
    "        with eng.connect() as con:\n",
    "            res = con.execute(f'select corpo from resultados limit {self.ndocs};')\n",
    "            for doc in res:\n",
    "                if process:\n",
    "                    d = self.pre_process(doc[0])\n",
    "                else: \n",
    "                    d = doc[0]\n",
    "                if self.counter%10 == 0:\n",
    "                    print (f\"Verbete {self.counter} de {self.ndocs}\\r\", end='')\n",
    "                \n",
    "                yield d\n",
    "                self.counter += 1\n",
    "    def pre_process(self, doc):\n",
    "        n = nlp(doc, disable=['tagger', 'ner','entity-linker', 'textcat','entity-ruler','merge-noun-chunks','merge-entities','merge-subtokens'])\n",
    "        results = [token.text.strip().strip(punctuation) for token in n if not token.is_stop]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Modelo Word2vec\n",
    "Vamos utilizar a representação vetorial do corpus construida anteriormente como base para o treinamento do classificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:34:08.304822Z",
     "start_time": "2020-11-30T17:34:07.810137Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('dhbb.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:34:15.885416Z",
     "start_time": "2020-11-30T17:34:15.874539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38762, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como  o word2vec é uma representação vetorial do vocabulário do corpus, e desejamos treinar um modelo para classificar documentos, precisamos primeiro construir uma representação dos documentos do corpus no mesmo espaço vetorial gerado pelo Word2vec.\n",
    "\n",
    "Na função abaixo, contruimos um vetor de documento que é a média dos vetores das palavras únicas que este contém."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:40:43.282625Z",
     "start_time": "2020-11-30T17:40:43.276347Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def build_document_vector(text):\n",
    "    \"\"\"\n",
    "    Build a scaled vector for the document (mean of the words present in it)\n",
    "    :param text: document to be vectorized (tokenized)\n",
    "    :param model: word2vec model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    feature_count = model.wv.vectors.shape[1]\n",
    "    vec = np.zeros(feature_count).reshape((1, feature_count))\n",
    "    count = 0.\n",
    "    \n",
    "\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += model.wv[word].reshape((1, feature_count))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:41:54.655197Z",
     "start_time": "2020-11-30T17:41:54.651623Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def gera_docv(n):\n",
    "    corpus = DHBBCorpus(n)\n",
    "    for doc in corpus:\n",
    "        v = build_document_vector(set(doc))\n",
    "        yield v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados treinamento do Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:58:00.671951Z",
     "start_time": "2020-11-30T17:43:32.994404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbete 7680 de 7687\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.329596</td>\n",
       "      <td>-0.396530</td>\n",
       "      <td>-0.234968</td>\n",
       "      <td>-0.008919</td>\n",
       "      <td>-0.392844</td>\n",
       "      <td>0.082079</td>\n",
       "      <td>0.643818</td>\n",
       "      <td>-0.036871</td>\n",
       "      <td>-0.374934</td>\n",
       "      <td>0.124961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081099</td>\n",
       "      <td>-0.177185</td>\n",
       "      <td>-0.233904</td>\n",
       "      <td>0.033541</td>\n",
       "      <td>0.796993</td>\n",
       "      <td>0.192985</td>\n",
       "      <td>0.214785</td>\n",
       "      <td>-0.679149</td>\n",
       "      <td>-0.522531</td>\n",
       "      <td>0.060596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.035577</td>\n",
       "      <td>-0.055027</td>\n",
       "      <td>-0.201358</td>\n",
       "      <td>0.587101</td>\n",
       "      <td>0.143018</td>\n",
       "      <td>0.238591</td>\n",
       "      <td>0.210333</td>\n",
       "      <td>-0.110109</td>\n",
       "      <td>-0.065921</td>\n",
       "      <td>0.119309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346693</td>\n",
       "      <td>0.047858</td>\n",
       "      <td>-0.110081</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>0.261467</td>\n",
       "      <td>0.295954</td>\n",
       "      <td>0.172945</td>\n",
       "      <td>-0.311859</td>\n",
       "      <td>-0.530189</td>\n",
       "      <td>0.316330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.197316</td>\n",
       "      <td>-0.189868</td>\n",
       "      <td>-0.271159</td>\n",
       "      <td>0.113843</td>\n",
       "      <td>-0.215909</td>\n",
       "      <td>0.009961</td>\n",
       "      <td>0.067409</td>\n",
       "      <td>-0.324156</td>\n",
       "      <td>-0.115856</td>\n",
       "      <td>-0.001585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189233</td>\n",
       "      <td>0.419339</td>\n",
       "      <td>-0.113524</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>0.213817</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>-0.033972</td>\n",
       "      <td>-0.277325</td>\n",
       "      <td>0.123685</td>\n",
       "      <td>0.069090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014647</td>\n",
       "      <td>-0.066778</td>\n",
       "      <td>-0.286216</td>\n",
       "      <td>0.386036</td>\n",
       "      <td>-0.009316</td>\n",
       "      <td>0.152754</td>\n",
       "      <td>0.165088</td>\n",
       "      <td>-0.023266</td>\n",
       "      <td>-0.212305</td>\n",
       "      <td>0.176561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200119</td>\n",
       "      <td>0.120266</td>\n",
       "      <td>0.037666</td>\n",
       "      <td>0.046779</td>\n",
       "      <td>-0.003079</td>\n",
       "      <td>0.229816</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>-0.170485</td>\n",
       "      <td>-0.298309</td>\n",
       "      <td>0.350582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090165</td>\n",
       "      <td>-0.315809</td>\n",
       "      <td>-0.481903</td>\n",
       "      <td>0.149809</td>\n",
       "      <td>-0.619123</td>\n",
       "      <td>-0.187226</td>\n",
       "      <td>0.241048</td>\n",
       "      <td>0.623205</td>\n",
       "      <td>-0.761205</td>\n",
       "      <td>0.581968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>-0.045994</td>\n",
       "      <td>-0.384362</td>\n",
       "      <td>-0.425419</td>\n",
       "      <td>1.413234</td>\n",
       "      <td>0.333866</td>\n",
       "      <td>0.776052</td>\n",
       "      <td>-0.494529</td>\n",
       "      <td>-1.045886</td>\n",
       "      <td>0.075690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>-0.090562</td>\n",
       "      <td>-0.084047</td>\n",
       "      <td>-0.383710</td>\n",
       "      <td>0.592161</td>\n",
       "      <td>-0.068067</td>\n",
       "      <td>0.279899</td>\n",
       "      <td>0.319775</td>\n",
       "      <td>-0.228383</td>\n",
       "      <td>-0.037196</td>\n",
       "      <td>-0.028221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274444</td>\n",
       "      <td>0.016063</td>\n",
       "      <td>-0.305153</td>\n",
       "      <td>0.150342</td>\n",
       "      <td>0.168861</td>\n",
       "      <td>0.206285</td>\n",
       "      <td>0.045919</td>\n",
       "      <td>-0.311792</td>\n",
       "      <td>-0.619057</td>\n",
       "      <td>0.102819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683</th>\n",
       "      <td>0.287989</td>\n",
       "      <td>-0.194534</td>\n",
       "      <td>-0.632097</td>\n",
       "      <td>0.139947</td>\n",
       "      <td>-1.013919</td>\n",
       "      <td>-0.531953</td>\n",
       "      <td>0.278965</td>\n",
       "      <td>0.712771</td>\n",
       "      <td>-0.324023</td>\n",
       "      <td>0.646100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502793</td>\n",
       "      <td>-0.146258</td>\n",
       "      <td>-0.535257</td>\n",
       "      <td>-0.699357</td>\n",
       "      <td>1.315595</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>-0.346391</td>\n",
       "      <td>-0.613722</td>\n",
       "      <td>-0.205855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7684</th>\n",
       "      <td>-0.294879</td>\n",
       "      <td>-0.429416</td>\n",
       "      <td>-0.505813</td>\n",
       "      <td>0.075155</td>\n",
       "      <td>-0.216774</td>\n",
       "      <td>0.174914</td>\n",
       "      <td>0.491742</td>\n",
       "      <td>0.038708</td>\n",
       "      <td>-0.140709</td>\n",
       "      <td>0.058136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011171</td>\n",
       "      <td>-0.008312</td>\n",
       "      <td>-0.336977</td>\n",
       "      <td>-0.009365</td>\n",
       "      <td>0.171825</td>\n",
       "      <td>0.423463</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>-0.400308</td>\n",
       "      <td>-0.435773</td>\n",
       "      <td>0.207956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7685</th>\n",
       "      <td>0.133161</td>\n",
       "      <td>-0.206598</td>\n",
       "      <td>-0.060065</td>\n",
       "      <td>0.013977</td>\n",
       "      <td>-0.309454</td>\n",
       "      <td>0.137658</td>\n",
       "      <td>0.484802</td>\n",
       "      <td>-0.104421</td>\n",
       "      <td>-0.151667</td>\n",
       "      <td>0.270099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025340</td>\n",
       "      <td>-0.111797</td>\n",
       "      <td>-0.485028</td>\n",
       "      <td>-0.052700</td>\n",
       "      <td>0.432771</td>\n",
       "      <td>0.114540</td>\n",
       "      <td>0.181120</td>\n",
       "      <td>-0.433214</td>\n",
       "      <td>-0.202734</td>\n",
       "      <td>0.052010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686</th>\n",
       "      <td>0.132097</td>\n",
       "      <td>-0.073985</td>\n",
       "      <td>-0.214157</td>\n",
       "      <td>0.329413</td>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.258794</td>\n",
       "      <td>0.047333</td>\n",
       "      <td>-0.096266</td>\n",
       "      <td>-0.139045</td>\n",
       "      <td>0.185727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139786</td>\n",
       "      <td>0.383356</td>\n",
       "      <td>0.051125</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.088136</td>\n",
       "      <td>0.132211</td>\n",
       "      <td>-0.033077</td>\n",
       "      <td>-0.147892</td>\n",
       "      <td>-0.116214</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7687 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.329596 -0.396530 -0.234968 -0.008919 -0.392844  0.082079  0.643818   \n",
       "1    -0.035577 -0.055027 -0.201358  0.587101  0.143018  0.238591  0.210333   \n",
       "2     0.197316 -0.189868 -0.271159  0.113843 -0.215909  0.009961  0.067409   \n",
       "3     0.014647 -0.066778 -0.286216  0.386036 -0.009316  0.152754  0.165088   \n",
       "4     0.090165 -0.315809 -0.481903  0.149809 -0.619123 -0.187226  0.241048   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7682 -0.090562 -0.084047 -0.383710  0.592161 -0.068067  0.279899  0.319775   \n",
       "7683  0.287989 -0.194534 -0.632097  0.139947 -1.013919 -0.531953  0.278965   \n",
       "7684 -0.294879 -0.429416 -0.505813  0.075155 -0.216774  0.174914  0.491742   \n",
       "7685  0.133161 -0.206598 -0.060065  0.013977 -0.309454  0.137658  0.484802   \n",
       "7686  0.132097 -0.073985 -0.214157  0.329413  0.025007  0.258794  0.047333   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0    -0.036871 -0.374934  0.124961  ... -0.081099 -0.177185 -0.233904   \n",
       "1    -0.110109 -0.065921  0.119309  ...  0.346693  0.047858 -0.110081   \n",
       "2    -0.324156 -0.115856 -0.001585  ... -0.189233  0.419339 -0.113524   \n",
       "3    -0.023266 -0.212305  0.176561  ...  0.200119  0.120266  0.037666   \n",
       "4     0.623205 -0.761205  0.581968  ...  0.061845 -0.045994 -0.384362   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7682 -0.228383 -0.037196 -0.028221  ...  0.274444  0.016063 -0.305153   \n",
       "7683  0.712771 -0.324023  0.646100  ... -0.502793 -0.146258 -0.535257   \n",
       "7684  0.038708 -0.140709  0.058136  ... -0.011171 -0.008312 -0.336977   \n",
       "7685 -0.104421 -0.151667  0.270099  ... -0.025340 -0.111797 -0.485028   \n",
       "7686 -0.096266 -0.139045  0.185727  ...  0.139786  0.383356  0.051125   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.033541  0.796993  0.192985  0.214785 -0.679149 -0.522531  0.060596  \n",
       "1     0.132066  0.261467  0.295954  0.172945 -0.311859 -0.530189  0.316330  \n",
       "2     0.013359  0.213817  0.028746 -0.033972 -0.277325  0.123685  0.069090  \n",
       "3     0.046779 -0.003079  0.229816  0.004536 -0.170485 -0.298309  0.350582  \n",
       "4    -0.425419  1.413234  0.333866  0.776052 -0.494529 -1.045886  0.075690  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7682  0.150342  0.168861  0.206285  0.045919 -0.311792 -0.619057  0.102819  \n",
       "7683 -0.699357  1.315595  0.183300  0.142800 -0.346391 -0.613722 -0.205855  \n",
       "7684 -0.009365  0.171825  0.423463  0.004228 -0.400308 -0.435773  0.207956  \n",
       "7685 -0.052700  0.432771  0.114540  0.181120 -0.433214 -0.202734  0.052010  \n",
       "7686  0.028334  0.088136  0.132211 -0.033077 -0.147892 -0.116214  0.253421  \n",
       "\n",
       "[7687 rows x 100 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerador = gera_docv(10000)\n",
    "data = pd.DataFrame(data=np.vstack([a for a in gerador]), columns=range(100))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('doc_feature_matrix.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a categoria de cada documento para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:24:27.341662Z",
     "start_time": "2020-11-30T18:24:27.280922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gera_alvo():\n",
    "    df = pd.read_sql_query('select natureza from resultados', con=eng)\n",
    "    alvo = df.natureza.values=='biográfico'\n",
    "    return alvo\n",
    "Y = gera_alvo()\n",
    "len(Y)-sum(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:28:20.838969Z",
     "start_time": "2020-11-30T18:28:20.833619Z"
    }
   },
   "outputs": [],
   "source": [
    "biog = data.iloc[Y]\n",
    "tem = data.iloc[~Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:32:04.177663Z",
     "start_time": "2020-11-30T18:32:04.174054Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(list(range(1926)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:43:21.310931Z",
     "start_time": "2020-11-30T18:43:21.280822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1926\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.231764</td>\n",
       "      <td>0.125892</td>\n",
       "      <td>-0.309413</td>\n",
       "      <td>0.467041</td>\n",
       "      <td>0.067909</td>\n",
       "      <td>0.270142</td>\n",
       "      <td>0.488265</td>\n",
       "      <td>0.161830</td>\n",
       "      <td>-0.139096</td>\n",
       "      <td>0.168827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359506</td>\n",
       "      <td>-0.627537</td>\n",
       "      <td>-0.169116</td>\n",
       "      <td>0.118968</td>\n",
       "      <td>0.103693</td>\n",
       "      <td>0.363135</td>\n",
       "      <td>0.394279</td>\n",
       "      <td>-0.290780</td>\n",
       "      <td>-0.689042</td>\n",
       "      <td>0.469090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.299131</td>\n",
       "      <td>0.272209</td>\n",
       "      <td>-0.396761</td>\n",
       "      <td>0.124968</td>\n",
       "      <td>-0.318209</td>\n",
       "      <td>-0.331420</td>\n",
       "      <td>0.242123</td>\n",
       "      <td>-0.173468</td>\n",
       "      <td>-0.195712</td>\n",
       "      <td>-0.168918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242322</td>\n",
       "      <td>0.299476</td>\n",
       "      <td>-0.183619</td>\n",
       "      <td>0.117456</td>\n",
       "      <td>0.886434</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>-0.236572</td>\n",
       "      <td>-0.308029</td>\n",
       "      <td>-0.436498</td>\n",
       "      <td>0.076838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.011937</td>\n",
       "      <td>-0.284217</td>\n",
       "      <td>-0.134488</td>\n",
       "      <td>0.306887</td>\n",
       "      <td>-0.067446</td>\n",
       "      <td>0.305895</td>\n",
       "      <td>0.039491</td>\n",
       "      <td>-0.045978</td>\n",
       "      <td>-0.110668</td>\n",
       "      <td>0.159025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.290940</td>\n",
       "      <td>-0.083019</td>\n",
       "      <td>-0.019634</td>\n",
       "      <td>-0.299745</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>-0.110135</td>\n",
       "      <td>-0.196507</td>\n",
       "      <td>-0.035130</td>\n",
       "      <td>0.067366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.324995</td>\n",
       "      <td>-0.262914</td>\n",
       "      <td>-0.949141</td>\n",
       "      <td>0.115911</td>\n",
       "      <td>-0.072201</td>\n",
       "      <td>0.404866</td>\n",
       "      <td>0.331368</td>\n",
       "      <td>0.036358</td>\n",
       "      <td>-0.389189</td>\n",
       "      <td>0.361507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>-0.341709</td>\n",
       "      <td>-0.121561</td>\n",
       "      <td>-0.174033</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.177809</td>\n",
       "      <td>0.145267</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>-0.543534</td>\n",
       "      <td>0.257592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.556185</td>\n",
       "      <td>-0.037645</td>\n",
       "      <td>-0.775895</td>\n",
       "      <td>0.685815</td>\n",
       "      <td>0.014939</td>\n",
       "      <td>0.102216</td>\n",
       "      <td>0.697670</td>\n",
       "      <td>0.215548</td>\n",
       "      <td>-0.167642</td>\n",
       "      <td>0.395696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192495</td>\n",
       "      <td>-0.529890</td>\n",
       "      <td>-0.315884</td>\n",
       "      <td>-0.284848</td>\n",
       "      <td>0.324406</td>\n",
       "      <td>0.321341</td>\n",
       "      <td>0.221229</td>\n",
       "      <td>-0.321057</td>\n",
       "      <td>-1.078787</td>\n",
       "      <td>0.331237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>0.084441</td>\n",
       "      <td>-0.224996</td>\n",
       "      <td>-0.088150</td>\n",
       "      <td>0.223650</td>\n",
       "      <td>-0.088020</td>\n",
       "      <td>0.258850</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>-0.070480</td>\n",
       "      <td>-0.045378</td>\n",
       "      <td>0.192008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>0.338718</td>\n",
       "      <td>-0.051668</td>\n",
       "      <td>0.033178</td>\n",
       "      <td>-0.289099</td>\n",
       "      <td>-0.072669</td>\n",
       "      <td>-0.118970</td>\n",
       "      <td>-0.156305</td>\n",
       "      <td>0.048619</td>\n",
       "      <td>0.060826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>0.022347</td>\n",
       "      <td>0.067674</td>\n",
       "      <td>-0.260271</td>\n",
       "      <td>0.370950</td>\n",
       "      <td>0.076030</td>\n",
       "      <td>-0.125611</td>\n",
       "      <td>0.296759</td>\n",
       "      <td>-0.252183</td>\n",
       "      <td>-0.406507</td>\n",
       "      <td>0.039033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215083</td>\n",
       "      <td>-0.241049</td>\n",
       "      <td>0.091856</td>\n",
       "      <td>-0.039028</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.068483</td>\n",
       "      <td>0.081157</td>\n",
       "      <td>-0.225349</td>\n",
       "      <td>-0.502597</td>\n",
       "      <td>0.329418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>-0.181316</td>\n",
       "      <td>-0.338150</td>\n",
       "      <td>-0.018350</td>\n",
       "      <td>-0.204138</td>\n",
       "      <td>0.061993</td>\n",
       "      <td>0.046468</td>\n",
       "      <td>-0.201608</td>\n",
       "      <td>-0.200506</td>\n",
       "      <td>0.165594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171176</td>\n",
       "      <td>0.405644</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.025316</td>\n",
       "      <td>0.025720</td>\n",
       "      <td>0.026260</td>\n",
       "      <td>-0.070545</td>\n",
       "      <td>-0.134418</td>\n",
       "      <td>0.140154</td>\n",
       "      <td>0.129406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>-0.174476</td>\n",
       "      <td>0.151847</td>\n",
       "      <td>-0.491045</td>\n",
       "      <td>0.554362</td>\n",
       "      <td>0.065269</td>\n",
       "      <td>0.075475</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>0.308236</td>\n",
       "      <td>-0.130147</td>\n",
       "      <td>0.169698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221611</td>\n",
       "      <td>-0.501535</td>\n",
       "      <td>-0.196038</td>\n",
       "      <td>-0.086404</td>\n",
       "      <td>0.175065</td>\n",
       "      <td>0.478218</td>\n",
       "      <td>0.238561</td>\n",
       "      <td>-0.526205</td>\n",
       "      <td>-0.690310</td>\n",
       "      <td>0.485502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>0.122671</td>\n",
       "      <td>-0.116640</td>\n",
       "      <td>-0.304865</td>\n",
       "      <td>0.222508</td>\n",
       "      <td>0.035899</td>\n",
       "      <td>0.187896</td>\n",
       "      <td>0.026410</td>\n",
       "      <td>0.017367</td>\n",
       "      <td>-0.202148</td>\n",
       "      <td>0.210361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043653</td>\n",
       "      <td>0.261592</td>\n",
       "      <td>0.113539</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.151173</td>\n",
       "      <td>0.227842</td>\n",
       "      <td>-0.027586</td>\n",
       "      <td>-0.119433</td>\n",
       "      <td>-0.267902</td>\n",
       "      <td>0.258780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1926 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.231764  0.125892 -0.309413  0.467041  0.067909  0.270142  0.488265   \n",
       "1     0.299131  0.272209 -0.396761  0.124968 -0.318209 -0.331420  0.242123   \n",
       "2    -0.011937 -0.284217 -0.134488  0.306887 -0.067446  0.305895  0.039491   \n",
       "3    -0.324995 -0.262914 -0.949141  0.115911 -0.072201  0.404866  0.331368   \n",
       "4    -0.556185 -0.037645 -0.775895  0.685815  0.014939  0.102216  0.697670   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1921  0.084441 -0.224996 -0.088150  0.223650 -0.088020  0.258850  0.031919   \n",
       "1922  0.022347  0.067674 -0.260271  0.370950  0.076030 -0.125611  0.296759   \n",
       "1923  0.130000 -0.181316 -0.338150 -0.018350 -0.204138  0.061993  0.046468   \n",
       "1924 -0.174476  0.151847 -0.491045  0.554362  0.065269  0.075475  0.506889   \n",
       "1925  0.122671 -0.116640 -0.304865  0.222508  0.035899  0.187896  0.026410   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     0.161830 -0.139096  0.168827  ...  0.359506 -0.627537 -0.169116   \n",
       "1    -0.173468 -0.195712 -0.168918  ... -0.242322  0.299476 -0.183619   \n",
       "2    -0.045978 -0.110668  0.159025  ...  0.058282  0.290940 -0.083019   \n",
       "3     0.036358 -0.389189  0.361507  ...  0.003018 -0.341709 -0.121561   \n",
       "4     0.215548 -0.167642  0.395696  ...  0.192495 -0.529890 -0.315884   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1921 -0.070480 -0.045378  0.192008  ...  0.094985  0.338718 -0.051668   \n",
       "1922 -0.252183 -0.406507  0.039033  ... -0.215083 -0.241049  0.091856   \n",
       "1923 -0.201608 -0.200506  0.165594  ... -0.171176  0.405644 -0.000176   \n",
       "1924  0.308236 -0.130147  0.169698  ...  0.221611 -0.501535 -0.196038   \n",
       "1925  0.017367 -0.202148  0.210361  ...  0.043653  0.261592  0.113539   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.118968  0.103693  0.363135  0.394279 -0.290780 -0.689042  0.469090  \n",
       "1     0.117456  0.886434  0.232356 -0.236572 -0.308029 -0.436498  0.076838  \n",
       "2    -0.019634 -0.299745  0.002079 -0.110135 -0.196507 -0.035130  0.067366  \n",
       "3    -0.174033  0.008716  0.177809  0.145267 -0.155198 -0.543534  0.257592  \n",
       "4    -0.284848  0.324406  0.321341  0.221229 -0.321057 -1.078787  0.331237  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1921  0.033178 -0.289099 -0.072669 -0.118970 -0.156305  0.048619  0.060826  \n",
       "1922 -0.039028 -0.001720  0.068483  0.081157 -0.225349 -0.502597  0.329418  \n",
       "1923 -0.025316  0.025720  0.026260 -0.070545 -0.134418  0.140154  0.129406  \n",
       "1924 -0.086404  0.175065  0.478218  0.238561 -0.526205 -0.690310  0.485502  \n",
       "1925 -0.001129  0.151173  0.227842 -0.027586 -0.119433 -0.267902  0.258780  \n",
       "\n",
       "[1926 rows x 100 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.concat([biog[:963],tem],axis=0)\n",
    "Y2 = np.array([True]*963 + [False]*963)\n",
    "data2['Y2'] = Y2\n",
    "data2 = data2.sample(frac=1).reset_index(drop=True)\n",
    "Y2 = data2.pop('Y2')\n",
    "print(len(Y2))\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:32:29.649797Z",
     "start_time": "2020-11-30T18:32:29.634372Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "def print_class_report(Xtest, Ytest, clf, clf_name):\n",
    "    \"\"\"\n",
    "    Prints Classification report\n",
    "    :param Xtest:\n",
    "    :param Ytest:\n",
    "    :param clf: trained classifier\n",
    "    :param clf_name: Name for the classifier\n",
    "    \"\"\"\n",
    "    y_predict = clf.predict(Xtest)\n",
    "    print('\\nClassification Report for {}:\\n'.format(clf_name))\n",
    "    print(classification_report(Ytest, y_predict, target_names=['Temático', 'Biográfico']))\n",
    "    \n",
    "\n",
    "def plot_roc(probas):\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "\n",
    "\n",
    "    labels = ['False positive rate', 'True Positive rate']\n",
    "    for k, v in probas.items():\n",
    "        roc_aucs = []\n",
    "        for j, fold in enumerate(v):\n",
    "            try:\n",
    "                fpr, tpr, thresholds = roc_curve(fold[1], fold[0][:, 1])\n",
    "            except IndexError:\n",
    "                print(fold[0], fold[0].shape)\n",
    "                continue\n",
    "            roc_aucs.append(auc(fpr, tpr))\n",
    "            tprs.append([float(t) for t in tpr])\n",
    "            fprs.append([float(f) for f in fpr])\n",
    "\n",
    "        print('{}: AUCs: {}'.format(k, str(roc_aucs)))\n",
    "    plt.scatter(fprs, tprs, [], \"ROC curve\", \"points\", 0, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:44:00.779645Z",
     "start_time": "2020-11-30T18:44:00.776156Z"
    }
   },
   "outputs": [],
   "source": [
    "rfclf = RandomForestClassifier(n_estimators=400, criterion='entropy', n_jobs=-1, min_samples_leaf=3, warm_start=True, verbose=0)\n",
    "etclf = ExtraTreesClassifier(n_estimators=400, n_jobs=-1,min_samples_leaf=3, warm_start=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:44:02.383716Z",
     "start_time": "2020-11-30T18:44:02.378315Z"
    }
   },
   "outputs": [],
   "source": [
    "vcclf = VotingClassifier(estimators=[('rf', rfclf), ('et', etclf)], voting='soft', weights=[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e validando o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:44:29.894265Z",
     "start_time": "2020-11-30T18:44:07.017710Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1926, 100) (1926,)\n",
      "(1926, 100)\n",
      "(1444, 100) (482, 100) (1444,) (482,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "==> Fitting:\n",
      "==> Extra Trees\n",
      "Random Forest\n",
      "Voting\n",
      "==> Scoring:\n",
      "==> Fitting:\n",
      "==> Extra Trees\n",
      "Random Forest\n",
      "Voting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fccoelho/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:455: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\n",
      "/home/fccoelho/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:455: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Scoring:\n",
      "==> Fitting:\n",
      "==> Extra Trees\n",
      "Random Forest\n",
      "Voting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fccoelho/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:455: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\n",
      "/home/fccoelho/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:455: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Scoring:\n",
      "\n",
      "Classification Report for ET:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       1.00      0.01      0.02       244\n",
      "  Biográfico       0.50      1.00      0.66       238\n",
      "\n",
      "    accuracy                           0.50       482\n",
      "   macro avg       0.75      0.50      0.34       482\n",
      "weighted avg       0.75      0.50      0.34       482\n",
      "\n",
      "\n",
      "Classification Report for RF:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       1.00      0.16      0.28       244\n",
      "  Biográfico       0.54      1.00      0.70       238\n",
      "\n",
      "    accuracy                           0.57       482\n",
      "   macro avg       0.77      0.58      0.49       482\n",
      "weighted avg       0.77      0.57      0.48       482\n",
      "\n",
      "\n",
      "Classification Report for Voting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       1.00      0.04      0.07       244\n",
      "  Biográfico       0.50      1.00      0.67       238\n",
      "\n",
      "    accuracy                           0.51       482\n",
      "   macro avg       0.75      0.52      0.37       482\n",
      "weighted avg       0.75      0.51      0.37       482\n",
      "\n",
      "RF: AUCs: [0.9933023415977962, 0.9954873958297313, 0.9954183955739973]\n",
      "[0.29619792 0.70380208] (2,)\n",
      "[0.00536458 0.99463542] (2,)\n",
      "[0.05657292 0.94342708] (2,)\n",
      "Voting: AUCs: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2826: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "s must be a scalar, or float array-like with the same size as x and y",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1200237/1632129954.py\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#     plot_learning(acc_hist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mplot_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# print('trained {} documents.'.format((n+1)*batchsize))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1200237/1327392209.py\u001b[0m in \u001b[0;36mplot_roc\u001b[0;34m(probas)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}: AUCs: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_aucs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfprs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtprs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ROC curve\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"points\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2815\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2816\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 2817\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   2818\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2819\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 (not np.issubdtype(s.dtype, np.floating) and\n\u001b[1;32m   4376\u001b[0m                  not np.issubdtype(s.dtype, np.integer))):\n\u001b[0;32m-> 4377\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   4378\u001b[0m                 \u001b[0;34m\"s must be a scalar, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4379\u001b[0m                 \"or float array-like with the same size as x and y\")\n",
      "\u001b[0;31mValueError\u001b[0m: s must be a scalar, or float array-like with the same size as x and y"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "scaler = StandardScaler()\n",
    "\n",
    "acc_hist = defaultdict(lambda: [])\n",
    "X2 = data2.values\n",
    "print(X2.shape, Y2.shape)\n",
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(X2,Y2.values, test_size=.25)\n",
    "print(X2.shape)\n",
    "print(Xtrain.shape,Xtest.shape,Ytrain.shape,Ytest.shape)\n",
    "probas = defaultdict(lambda: [])\n",
    "skf = StratifiedKFold(3, shuffle=True)\n",
    "print (type(Xtrain),type(Ytrain))\n",
    "for train_index, test_index in skf.split(Xtrain, Ytrain):\n",
    "    scaler.fit(Xtrain)\n",
    "    Xtr = scaler.transform(Xtrain[train_index])\n",
    "    Xte = Xtrain[test_index]\n",
    "    print(\"==> Fitting:\")\n",
    "    print(\"==> Extra Trees\")\n",
    "    etclf.fit(Xtr,Ytrain[train_index])\n",
    "    print(\"Random Forest\")\n",
    "    rfclf.fit(Xtr, Ytrain[train_index])\n",
    "    probas['RF'].append((rfclf.predict_proba(Xte), Ytrain[test_index]))\n",
    "    print(\"Voting\")\n",
    "    vcclf.fit(Xtr, Ytrain[train_index])\n",
    "    probas['Voting'].append(vcclf.predict_proba(Xte))\n",
    "    print(\"==> Scoring:\")\n",
    "    acc_hist['ET'].append(cross_val_score(etclf, Xtest, Ytest, cv=2, n_jobs=-1).mean())\n",
    "\n",
    "    acc_hist['RF'].append(cross_val_score(rfclf, Xtest, Ytest, cv=2, n_jobs=-1).mean())\n",
    "    acc_hist['Voting'].append(vcclf.score(Xtest, Ytest))\n",
    "print_class_report(Xtest, Ytest, etclf, 'ET')\n",
    "print_class_report(Xtest, Ytest, rfclf, 'RF')\n",
    "print_class_report(Xtest, Ytest, vcclf, 'Voting')\n",
    "\n",
    "#     plot_learning(acc_hist)\n",
    "plot_roc(probas)\n",
    "\n",
    "# print('trained {} documents.'.format((n+1)*batchsize))\n",
    "df_acc = pd.DataFrame(acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:34:46.459934Z",
     "start_time": "2020-11-30T18:34:46.451084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1444, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:34:47.200538Z",
     "start_time": "2020-11-30T18:34:47.195068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702    False\n",
       "906      True\n",
       "291     False\n",
       "1227     True\n",
       "1059     True\n",
       "        ...  \n",
       "444     False\n",
       "270     False\n",
       "1635     True\n",
       "1284     True\n",
       "1371     True\n",
       "Name: Y2, Length: 1444, dtype: bool"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True, False, False, False, False,\n",
       "       False,  True, False, False, False,  True, False, False,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True, False, False,  True,  True,\n",
       "        True,  True, False,  True,  True, False, False,  True,  True,\n",
       "       False,  True,  True, False, False, False,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "       False,  True,  True, False,  True, False, False, False,  True,\n",
       "       False,  True, False,  True, False,  True, False,  True, False,\n",
       "        True, False, False, False,  True,  True, False,  True, False,\n",
       "       False, False,  True, False,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False, False,  True,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "       False,  True, False,  True,  True,  True, False,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False,  True,  True,  True,  True, False, False, False,  True,\n",
       "        True,  True, False,  True, False,  True, False, False, False,\n",
       "        True, False, False,  True, False,  True,  True,  True, False,\n",
       "        True, False, False,  True,  True,  True, False,  True, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "        True, False, False,  True,  True,  True, False, False,  True,\n",
       "        True,  True, False,  True, False,  True,  True,  True, False,\n",
       "        True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True, False, False,  True,  True, False,  True,\n",
       "        True,  True, False,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True, False, False, False, False,  True,\n",
       "       False,  True, False, False, False,  True, False, False,  True,\n",
       "        True,  True, False,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True, False, False, False,  True, False,\n",
       "       False,  True, False, False, False,  True, False, False,  True,\n",
       "        True,  True, False, False, False, False, False,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True,  True,  True,  True, False,\n",
       "       False,  True, False,  True,  True, False, False, False,  True,\n",
       "       False,  True,  True, False, False, False,  True, False,  True,\n",
       "        True,  True, False, False, False,  True, False, False,  True,\n",
       "        True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "        True,  True, False,  True, False,  True, False,  True, False,\n",
       "       False,  True, False, False,  True,  True, False, False, False,\n",
       "        True, False,  True, False,  True,  True, False,  True, False,\n",
       "        True, False,  True,  True,  True, False, False,  True, False,\n",
       "       False, False,  True, False,  True,  True,  True, False, False,\n",
       "        True, False, False, False,  True, False, False,  True,  True,\n",
       "        True, False, False,  True, False,  True, False, False,  True,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "        True,  True,  True,  True, False,  True, False,  True, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False,  True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.values[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with a different feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "corpus = DHBBCorpus(n)\n",
    "X_train_counts = count_vect.fit_transform(corpus)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 350,
   "position": {
    "height": "40px",
    "left": "651px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
