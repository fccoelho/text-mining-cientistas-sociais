{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo um Classificador de Textos\n",
    "Uma das aplicações mais comuns em mineração de textos é a classificações de documentos em categorias pré-definidas, sejam elas autorais, temáticas, temporais ou outras. \n",
    "\n",
    "Neste capítulo iremos explorar os passos necessários para o desenvolvimento de um classificador de documentos utilizando as análises feitas sobre o corpus do DHBB nos capítulos anteriores.\n",
    "\n",
    "Para esta tarefa utilizaremos modelos de machine learning clássicos disponibilizados na biblioteca [Scikit-Learn](https://scikit-learn.org/). Começaremos então importando algumas funcionalidades a partir do Scikit-Learn. Os demais imports já foram utilizados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:11:52.781057Z",
     "start_time": "2020-11-30T18:11:52.776773Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gensim.models import Word2Vec, word2vec\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from string import punctuation\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o corpus\n",
    "Vamos utilizar o corpus do DHBB conforme armazenado na biblioteca SQLite anteriormente. Abaixo iremos desenvolver um iterador sobre o corpus que fará um preprocessamento básico dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:33:38.508266Z",
     "start_time": "2020-11-30T17:33:35.735062Z"
    }
   },
   "outputs": [],
   "source": [
    "eng = create_engine(\"sqlite:///minha_tabela.sqlite\")\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "class DHBBCorpus:\n",
    "    def __init__(self, ndocs=10000):\n",
    "        self.ndocs = min(7687,ndocs)\n",
    "        self.counter = 1\n",
    "    def __iter__(self):\n",
    "        with eng.connect() as con:\n",
    "            res = con.execute(f'select corpo from resultados limit {self.ndocs};')\n",
    "            for doc in res:\n",
    "                d = self.pre_process(doc[0])\n",
    "                if self.counter%10 == 0:\n",
    "                    print (f\"Verbete {self.counter} de {self.ndocs}\\r\", end='')\n",
    "                \n",
    "                yield d\n",
    "                self.counter += 1\n",
    "    def pre_process(self, doc):\n",
    "        n = nlp(doc, disable=['tagger', 'ner','entity-linker', 'textcat','entity-ruler','merge-noun-chunks','merge-entities','merge-subtokens'])\n",
    "        results = [token.text.strip().strip(punctuation) for token in n if not token.is_stop]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Modelo Word2vec\n",
    "Vamos utilizar a representação vetorial do corpus construida anteriormente como base para o treinamento do classificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:34:08.304822Z",
     "start_time": "2020-11-30T17:34:07.810137Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('dhbb.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:34:15.885416Z",
     "start_time": "2020-11-30T17:34:15.874539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38762, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como  o word2vec é uma representação vetorial do vocabulário do corpus, e desejamos treinar um modelo para classificar documentos, precisamos primeiro construir uma representação dos documentos do corpus no mesmo espaço vetorial gerado pelo Word2vec.\n",
    "\n",
    "Na função abaixo, contruimos um vetor de documento que é a média dos vetores das palavras únicas que este contém."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:40:43.282625Z",
     "start_time": "2020-11-30T17:40:43.276347Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def build_document_vector(text):\n",
    "    \"\"\"\n",
    "    Build a scaled vector for the document (mean of the words present in it)\n",
    "    :param text: document to be vectorized (tokenized)\n",
    "    :param model: word2vec model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    feature_count = model.wv.vectors.shape[1]\n",
    "    vec = np.zeros(feature_count).reshape((1, feature_count))\n",
    "    count = 0.\n",
    "    \n",
    "\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += model.wv[word].reshape((1, feature_count))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:41:54.655197Z",
     "start_time": "2020-11-30T17:41:54.651623Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def gera_docv(n):\n",
    "    corpus = DHBBCorpus(n)\n",
    "    for doc in corpus:\n",
    "        v = build_document_vector(set(doc))\n",
    "        yield v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados treinamento do Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T17:58:00.671951Z",
     "start_time": "2020-11-30T17:43:32.994404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbete 7680 de 7687\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299355</td>\n",
       "      <td>-0.374758</td>\n",
       "      <td>-0.221921</td>\n",
       "      <td>-0.014266</td>\n",
       "      <td>-0.362556</td>\n",
       "      <td>0.058059</td>\n",
       "      <td>0.646023</td>\n",
       "      <td>-0.032011</td>\n",
       "      <td>-0.375196</td>\n",
       "      <td>0.106362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078524</td>\n",
       "      <td>-0.164474</td>\n",
       "      <td>-0.235533</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.767313</td>\n",
       "      <td>0.173925</td>\n",
       "      <td>0.212851</td>\n",
       "      <td>-0.657804</td>\n",
       "      <td>-0.501652</td>\n",
       "      <td>0.051704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.047586</td>\n",
       "      <td>-0.047138</td>\n",
       "      <td>-0.192919</td>\n",
       "      <td>0.581458</td>\n",
       "      <td>0.155535</td>\n",
       "      <td>0.226447</td>\n",
       "      <td>0.213957</td>\n",
       "      <td>-0.109043</td>\n",
       "      <td>-0.071011</td>\n",
       "      <td>0.108084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344092</td>\n",
       "      <td>0.060079</td>\n",
       "      <td>-0.120950</td>\n",
       "      <td>0.116963</td>\n",
       "      <td>0.260116</td>\n",
       "      <td>0.291860</td>\n",
       "      <td>0.169258</td>\n",
       "      <td>-0.301641</td>\n",
       "      <td>-0.520335</td>\n",
       "      <td>0.310200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.193163</td>\n",
       "      <td>-0.186792</td>\n",
       "      <td>-0.268551</td>\n",
       "      <td>0.111721</td>\n",
       "      <td>-0.208734</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.070133</td>\n",
       "      <td>-0.324108</td>\n",
       "      <td>-0.118932</td>\n",
       "      <td>-0.003408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189952</td>\n",
       "      <td>0.421482</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>0.213612</td>\n",
       "      <td>0.025497</td>\n",
       "      <td>-0.034283</td>\n",
       "      <td>-0.273559</td>\n",
       "      <td>0.126102</td>\n",
       "      <td>0.067360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006157</td>\n",
       "      <td>-0.060400</td>\n",
       "      <td>-0.279931</td>\n",
       "      <td>0.379012</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.142672</td>\n",
       "      <td>0.170820</td>\n",
       "      <td>-0.025366</td>\n",
       "      <td>-0.218879</td>\n",
       "      <td>0.170935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195555</td>\n",
       "      <td>0.127540</td>\n",
       "      <td>0.024253</td>\n",
       "      <td>0.031326</td>\n",
       "      <td>-0.001970</td>\n",
       "      <td>0.220645</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>-0.162352</td>\n",
       "      <td>-0.289485</td>\n",
       "      <td>0.344416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030312</td>\n",
       "      <td>-0.264496</td>\n",
       "      <td>-0.444708</td>\n",
       "      <td>0.091338</td>\n",
       "      <td>-0.521767</td>\n",
       "      <td>-0.225814</td>\n",
       "      <td>0.259753</td>\n",
       "      <td>0.601325</td>\n",
       "      <td>-0.751790</td>\n",
       "      <td>0.503691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047659</td>\n",
       "      <td>-0.016358</td>\n",
       "      <td>-0.346371</td>\n",
       "      <td>-0.465766</td>\n",
       "      <td>1.352994</td>\n",
       "      <td>0.284854</td>\n",
       "      <td>0.753584</td>\n",
       "      <td>-0.441544</td>\n",
       "      <td>-0.971092</td>\n",
       "      <td>0.049266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>-0.097823</td>\n",
       "      <td>-0.078891</td>\n",
       "      <td>-0.378231</td>\n",
       "      <td>0.586076</td>\n",
       "      <td>-0.060112</td>\n",
       "      <td>0.270353</td>\n",
       "      <td>0.322826</td>\n",
       "      <td>-0.225374</td>\n",
       "      <td>-0.039686</td>\n",
       "      <td>-0.033435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272789</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>-0.305199</td>\n",
       "      <td>0.141629</td>\n",
       "      <td>0.163269</td>\n",
       "      <td>0.199732</td>\n",
       "      <td>0.046464</td>\n",
       "      <td>-0.307171</td>\n",
       "      <td>-0.611295</td>\n",
       "      <td>0.099506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683</th>\n",
       "      <td>0.179406</td>\n",
       "      <td>-0.121504</td>\n",
       "      <td>-0.562740</td>\n",
       "      <td>0.047880</td>\n",
       "      <td>-0.832265</td>\n",
       "      <td>-0.569388</td>\n",
       "      <td>0.306019</td>\n",
       "      <td>0.671887</td>\n",
       "      <td>-0.339240</td>\n",
       "      <td>0.517512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486355</td>\n",
       "      <td>-0.092336</td>\n",
       "      <td>-0.464590</td>\n",
       "      <td>-0.744464</td>\n",
       "      <td>1.226775</td>\n",
       "      <td>0.115940</td>\n",
       "      <td>0.150833</td>\n",
       "      <td>-0.272562</td>\n",
       "      <td>-0.524888</td>\n",
       "      <td>-0.228353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7684</th>\n",
       "      <td>-0.305582</td>\n",
       "      <td>-0.415389</td>\n",
       "      <td>-0.494118</td>\n",
       "      <td>0.070715</td>\n",
       "      <td>-0.200167</td>\n",
       "      <td>0.158698</td>\n",
       "      <td>0.495111</td>\n",
       "      <td>0.040753</td>\n",
       "      <td>-0.143941</td>\n",
       "      <td>0.047398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010479</td>\n",
       "      <td>-0.002587</td>\n",
       "      <td>-0.336644</td>\n",
       "      <td>-0.023329</td>\n",
       "      <td>0.161481</td>\n",
       "      <td>0.408541</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>-0.390632</td>\n",
       "      <td>-0.423871</td>\n",
       "      <td>0.200473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7685</th>\n",
       "      <td>0.115212</td>\n",
       "      <td>-0.191013</td>\n",
       "      <td>-0.055094</td>\n",
       "      <td>-0.002285</td>\n",
       "      <td>-0.269068</td>\n",
       "      <td>0.113420</td>\n",
       "      <td>0.496748</td>\n",
       "      <td>-0.107383</td>\n",
       "      <td>-0.168153</td>\n",
       "      <td>0.263151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035157</td>\n",
       "      <td>-0.105682</td>\n",
       "      <td>-0.496205</td>\n",
       "      <td>-0.084804</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.080934</td>\n",
       "      <td>0.181313</td>\n",
       "      <td>-0.414772</td>\n",
       "      <td>-0.182550</td>\n",
       "      <td>0.041914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686</th>\n",
       "      <td>0.124736</td>\n",
       "      <td>-0.068924</td>\n",
       "      <td>-0.209627</td>\n",
       "      <td>0.324212</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>0.250245</td>\n",
       "      <td>0.052526</td>\n",
       "      <td>-0.097496</td>\n",
       "      <td>-0.144643</td>\n",
       "      <td>0.181247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136543</td>\n",
       "      <td>0.387558</td>\n",
       "      <td>0.040490</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>0.088481</td>\n",
       "      <td>0.125558</td>\n",
       "      <td>-0.033661</td>\n",
       "      <td>-0.141622</td>\n",
       "      <td>-0.110324</td>\n",
       "      <td>0.249130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7687 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.299355 -0.374758 -0.221921 -0.014266 -0.362556  0.058059  0.646023   \n",
       "1    -0.047586 -0.047138 -0.192919  0.581458  0.155535  0.226447  0.213957   \n",
       "2     0.193163 -0.186792 -0.268551  0.111721 -0.208734  0.006146  0.070133   \n",
       "3     0.006157 -0.060400 -0.279931  0.379012  0.006151  0.142672  0.170820   \n",
       "4     0.030312 -0.264496 -0.444708  0.091338 -0.521767 -0.225814  0.259753   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7682 -0.097823 -0.078891 -0.378231  0.586076 -0.060112  0.270353  0.322826   \n",
       "7683  0.179406 -0.121504 -0.562740  0.047880 -0.832265 -0.569388  0.306019   \n",
       "7684 -0.305582 -0.415389 -0.494118  0.070715 -0.200167  0.158698  0.495111   \n",
       "7685  0.115212 -0.191013 -0.055094 -0.002285 -0.269068  0.113420  0.496748   \n",
       "7686  0.124736 -0.068924 -0.209627  0.324212  0.036982  0.250245  0.052526   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0    -0.032011 -0.375196  0.106362  ... -0.078524 -0.164474 -0.235533   \n",
       "1    -0.109043 -0.071011  0.108084  ...  0.344092  0.060079 -0.120950   \n",
       "2    -0.324108 -0.118932 -0.003408  ... -0.189952  0.421482 -0.118719   \n",
       "3    -0.025366 -0.218879  0.170935  ...  0.195555  0.127540  0.024253   \n",
       "4     0.601325 -0.751790  0.503691  ...  0.047659 -0.016358 -0.346371   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7682 -0.225374 -0.039686 -0.033435  ...  0.272789  0.018996 -0.305199   \n",
       "7683  0.671887 -0.339240  0.517512  ... -0.486355 -0.092336 -0.464590   \n",
       "7684  0.040753 -0.143941  0.047398  ... -0.010479 -0.002587 -0.336644   \n",
       "7685 -0.107383 -0.168153  0.263151  ... -0.035157 -0.105682 -0.496205   \n",
       "7686 -0.097496 -0.144643  0.181247  ...  0.136543  0.387558  0.040490   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.010279  0.767313  0.173925  0.212851 -0.657804 -0.501652  0.051704  \n",
       "1     0.116963  0.260116  0.291860  0.169258 -0.301641 -0.520335  0.310200  \n",
       "2     0.006936  0.213612  0.025497 -0.034283 -0.273559  0.126102  0.067360  \n",
       "3     0.031326 -0.001970  0.220645  0.003517 -0.162352 -0.289485  0.344416  \n",
       "4    -0.465766  1.352994  0.284854  0.753584 -0.441544 -0.971092  0.049266  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7682  0.141629  0.163269  0.199732  0.046464 -0.307171 -0.611295  0.099506  \n",
       "7683 -0.744464  1.226775  0.115940  0.150833 -0.272562 -0.524888 -0.228353  \n",
       "7684 -0.023329  0.161481  0.408541  0.005779 -0.390632 -0.423871  0.200473  \n",
       "7685 -0.084804  0.417006  0.080934  0.181313 -0.414772 -0.182550  0.041914  \n",
       "7686  0.016278  0.088481  0.125558 -0.033661 -0.141622 -0.110324  0.249130  \n",
       "\n",
       "[7687 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerador = gera_docv(10000)\n",
    "data = pd.DataFrame(data=np.vstack([a for a in gerador]), columns=range(100))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a categoria de cada documento para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:24:27.341662Z",
     "start_time": "2020-11-30T18:24:27.280922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gera_alvo():\n",
    "    df = pd.read_sql_query('select natureza from resultados', con=eng)\n",
    "    alvo = df.natureza.values=='biográfico'\n",
    "    return alvo\n",
    "Y = gera_alvo()\n",
    "len(Y)-sum(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:28:20.838969Z",
     "start_time": "2020-11-30T18:28:20.833619Z"
    }
   },
   "outputs": [],
   "source": [
    "biog = data.iloc[Y]\n",
    "tem = data.iloc[~Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:32:04.177663Z",
     "start_time": "2020-11-30T18:32:04.174054Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(list(range(1926)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:43:21.310931Z",
     "start_time": "2020-11-30T18:43:21.280822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.287586</td>\n",
       "      <td>0.392659</td>\n",
       "      <td>-0.731287</td>\n",
       "      <td>0.627016</td>\n",
       "      <td>-0.042116</td>\n",
       "      <td>-0.104181</td>\n",
       "      <td>0.339614</td>\n",
       "      <td>0.169082</td>\n",
       "      <td>-0.124376</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151552</td>\n",
       "      <td>-0.554600</td>\n",
       "      <td>-0.420021</td>\n",
       "      <td>-0.156081</td>\n",
       "      <td>0.437308</td>\n",
       "      <td>0.750317</td>\n",
       "      <td>0.121929</td>\n",
       "      <td>-0.366128</td>\n",
       "      <td>-0.991161</td>\n",
       "      <td>0.489637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109333</td>\n",
       "      <td>-0.300749</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.283070</td>\n",
       "      <td>-0.123726</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>-0.048570</td>\n",
       "      <td>0.032761</td>\n",
       "      <td>0.176519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133429</td>\n",
       "      <td>0.438715</td>\n",
       "      <td>-0.051695</td>\n",
       "      <td>0.056249</td>\n",
       "      <td>-0.376985</td>\n",
       "      <td>-0.123494</td>\n",
       "      <td>-0.177922</td>\n",
       "      <td>-0.156822</td>\n",
       "      <td>0.122555</td>\n",
       "      <td>-0.048608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.297096</td>\n",
       "      <td>-0.127949</td>\n",
       "      <td>-0.654515</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.067958</td>\n",
       "      <td>0.016514</td>\n",
       "      <td>0.430008</td>\n",
       "      <td>0.222950</td>\n",
       "      <td>-0.428702</td>\n",
       "      <td>0.359814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199933</td>\n",
       "      <td>-0.778702</td>\n",
       "      <td>-0.294653</td>\n",
       "      <td>-0.259145</td>\n",
       "      <td>0.076912</td>\n",
       "      <td>0.379931</td>\n",
       "      <td>0.184168</td>\n",
       "      <td>-0.444600</td>\n",
       "      <td>-0.881913</td>\n",
       "      <td>0.457874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.181810</td>\n",
       "      <td>-0.061366</td>\n",
       "      <td>-0.338914</td>\n",
       "      <td>0.376706</td>\n",
       "      <td>-0.041893</td>\n",
       "      <td>0.136617</td>\n",
       "      <td>0.498730</td>\n",
       "      <td>-0.181095</td>\n",
       "      <td>-0.240299</td>\n",
       "      <td>0.184389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183034</td>\n",
       "      <td>-0.156569</td>\n",
       "      <td>-0.249727</td>\n",
       "      <td>-0.045820</td>\n",
       "      <td>0.042241</td>\n",
       "      <td>0.217679</td>\n",
       "      <td>0.112461</td>\n",
       "      <td>-0.107007</td>\n",
       "      <td>-0.475181</td>\n",
       "      <td>0.196008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.167694</td>\n",
       "      <td>-0.014426</td>\n",
       "      <td>-0.351949</td>\n",
       "      <td>0.304469</td>\n",
       "      <td>0.211838</td>\n",
       "      <td>0.401343</td>\n",
       "      <td>0.309968</td>\n",
       "      <td>0.245993</td>\n",
       "      <td>-0.207923</td>\n",
       "      <td>0.281746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259211</td>\n",
       "      <td>-0.137243</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>-0.034965</td>\n",
       "      <td>0.620501</td>\n",
       "      <td>0.619169</td>\n",
       "      <td>0.337761</td>\n",
       "      <td>-0.242318</td>\n",
       "      <td>-0.579613</td>\n",
       "      <td>0.505532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>0.344708</td>\n",
       "      <td>-0.181017</td>\n",
       "      <td>-0.147162</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>-0.210840</td>\n",
       "      <td>-0.029625</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>-0.294783</td>\n",
       "      <td>-0.089625</td>\n",
       "      <td>-0.034736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186432</td>\n",
       "      <td>0.505796</td>\n",
       "      <td>-0.050912</td>\n",
       "      <td>0.095325</td>\n",
       "      <td>0.103774</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>-0.107959</td>\n",
       "      <td>-0.238199</td>\n",
       "      <td>0.180362</td>\n",
       "      <td>0.081891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>0.287809</td>\n",
       "      <td>-0.193073</td>\n",
       "      <td>-0.335034</td>\n",
       "      <td>-0.007505</td>\n",
       "      <td>-0.293801</td>\n",
       "      <td>0.012606</td>\n",
       "      <td>0.366060</td>\n",
       "      <td>-0.364010</td>\n",
       "      <td>-0.234743</td>\n",
       "      <td>-0.010948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401236</td>\n",
       "      <td>0.316644</td>\n",
       "      <td>-0.056814</td>\n",
       "      <td>-0.025062</td>\n",
       "      <td>0.426827</td>\n",
       "      <td>0.071936</td>\n",
       "      <td>-0.110882</td>\n",
       "      <td>-0.337798</td>\n",
       "      <td>-0.082237</td>\n",
       "      <td>0.173368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>-0.026300</td>\n",
       "      <td>-0.045847</td>\n",
       "      <td>-0.166971</td>\n",
       "      <td>0.395506</td>\n",
       "      <td>0.043388</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.268256</td>\n",
       "      <td>0.095490</td>\n",
       "      <td>-0.105613</td>\n",
       "      <td>0.204073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223723</td>\n",
       "      <td>-0.001837</td>\n",
       "      <td>-0.111942</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>0.130912</td>\n",
       "      <td>0.213542</td>\n",
       "      <td>-0.071582</td>\n",
       "      <td>-0.117143</td>\n",
       "      <td>-0.304340</td>\n",
       "      <td>0.364136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>-0.217996</td>\n",
       "      <td>0.257454</td>\n",
       "      <td>-0.374343</td>\n",
       "      <td>0.571969</td>\n",
       "      <td>0.037497</td>\n",
       "      <td>0.110626</td>\n",
       "      <td>0.107253</td>\n",
       "      <td>0.224317</td>\n",
       "      <td>-0.407639</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241646</td>\n",
       "      <td>-0.559145</td>\n",
       "      <td>-0.312735</td>\n",
       "      <td>-0.056651</td>\n",
       "      <td>0.704004</td>\n",
       "      <td>0.435032</td>\n",
       "      <td>0.380705</td>\n",
       "      <td>-0.434107</td>\n",
       "      <td>-1.058273</td>\n",
       "      <td>0.222910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>0.219787</td>\n",
       "      <td>-0.186540</td>\n",
       "      <td>-0.246056</td>\n",
       "      <td>-0.004235</td>\n",
       "      <td>-0.215065</td>\n",
       "      <td>-0.002744</td>\n",
       "      <td>0.076173</td>\n",
       "      <td>-0.180295</td>\n",
       "      <td>-0.091237</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341556</td>\n",
       "      <td>0.445813</td>\n",
       "      <td>-0.060886</td>\n",
       "      <td>-0.124362</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>-0.074738</td>\n",
       "      <td>-0.204539</td>\n",
       "      <td>-0.211884</td>\n",
       "      <td>0.152408</td>\n",
       "      <td>0.005083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1926 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.287586  0.392659 -0.731287  0.627016 -0.042116 -0.104181  0.339614   \n",
       "1     0.109333 -0.300749  0.025365  0.283070 -0.123726  0.308500 -0.000194   \n",
       "2    -0.297096 -0.127949 -0.654515  0.292929  0.067958  0.016514  0.430008   \n",
       "3    -0.181810 -0.061366 -0.338914  0.376706 -0.041893  0.136617  0.498730   \n",
       "4    -0.167694 -0.014426 -0.351949  0.304469  0.211838  0.401343  0.309968   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1921  0.344708 -0.181017 -0.147162  0.043743 -0.210840 -0.029625  0.021876   \n",
       "1922  0.287809 -0.193073 -0.335034 -0.007505 -0.293801  0.012606  0.366060   \n",
       "1923 -0.026300 -0.045847 -0.166971  0.395506  0.043388  0.076857  0.268256   \n",
       "1924 -0.217996  0.257454 -0.374343  0.571969  0.037497  0.110626  0.107253   \n",
       "1925  0.219787 -0.186540 -0.246056 -0.004235 -0.215065 -0.002744  0.076173   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     0.169082 -0.124376  0.007306  ...  0.151552 -0.554600 -0.420021   \n",
       "1    -0.048570  0.032761  0.176519  ...  0.133429  0.438715 -0.051695   \n",
       "2     0.222950 -0.428702  0.359814  ...  0.199933 -0.778702 -0.294653   \n",
       "3    -0.181095 -0.240299  0.184389  ...  0.183034 -0.156569 -0.249727   \n",
       "4     0.245993 -0.207923  0.281746  ...  0.259211 -0.137243  0.003007   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1921 -0.294783 -0.089625 -0.034736  ... -0.186432  0.505796 -0.050912   \n",
       "1922 -0.364010 -0.234743 -0.010948  ... -0.401236  0.316644 -0.056814   \n",
       "1923  0.095490 -0.105613  0.204073  ...  0.223723 -0.001837 -0.111942   \n",
       "1924  0.224317 -0.407639  0.038237  ...  0.241646 -0.559145 -0.312735   \n",
       "1925 -0.180295 -0.091237  0.014444  ... -0.341556  0.445813 -0.060886   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0    -0.156081  0.437308  0.750317  0.121929 -0.366128 -0.991161  0.489637  \n",
       "1     0.056249 -0.376985 -0.123494 -0.177922 -0.156822  0.122555 -0.048608  \n",
       "2    -0.259145  0.076912  0.379931  0.184168 -0.444600 -0.881913  0.457874  \n",
       "3    -0.045820  0.042241  0.217679  0.112461 -0.107007 -0.475181  0.196008  \n",
       "4    -0.034965  0.620501  0.619169  0.337761 -0.242318 -0.579613  0.505532  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1921  0.095325  0.103774  0.005002 -0.107959 -0.238199  0.180362  0.081891  \n",
       "1922 -0.025062  0.426827  0.071936 -0.110882 -0.337798 -0.082237  0.173368  \n",
       "1923  0.014763  0.130912  0.213542 -0.071582 -0.117143 -0.304340  0.364136  \n",
       "1924 -0.056651  0.704004  0.435032  0.380705 -0.434107 -1.058273  0.222910  \n",
       "1925 -0.124362  0.006829 -0.074738 -0.204539 -0.211884  0.152408  0.005083  \n",
       "\n",
       "[1926 rows x 100 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.concat([biog[:963],tem],axis=0)\n",
    "Y2 = np.array([True]*963 + [False]*963)\n",
    "data2['Y2'] = Y2\n",
    "data2 = data2.sample(frac=1).reset_index(drop=True)\n",
    "Y2 = data2.pop('Y2')\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:32:29.649797Z",
     "start_time": "2020-11-30T18:32:29.634372Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "def print_class_report(Xtest, Ytest, clf, clf_name):\n",
    "    \"\"\"\n",
    "    Prints Classification report\n",
    "    :param Xtest:\n",
    "    :param Ytest:\n",
    "    :param clf: trained classifier\n",
    "    :param clf_name: Name for the classifier\n",
    "    \"\"\"\n",
    "    y_predict = clf.predict(Xtest)\n",
    "    print('\\nClassification Report for {}:\\n'.format(clf_name))\n",
    "    print(classification_report(Ytest, y_predict, target_names=['Temático', 'Biográfico']))\n",
    "    \n",
    "\n",
    "def plot_roc(probas):\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "\n",
    "\n",
    "    labels = ['False positive rate', 'True Positive rate']\n",
    "    for k, v in probas.items():\n",
    "        roc_aucs = []\n",
    "        for j, fold in enumerate(v):\n",
    "            try:\n",
    "                fpr, tpr, thresholds = roc_curve(fold[1], fold[0][:, 1])\n",
    "            except IndexError:\n",
    "                print(fold[0], fold[0].shape)\n",
    "                continue\n",
    "            roc_aucs.append(auc(fpr, tpr))\n",
    "            tprs.append([float(t) for t in tpr])\n",
    "            fprs.append([float(f) for f in fpr])\n",
    "\n",
    "        print('{}: AUCs: {}'.format(k, str(roc_aucs)))\n",
    "    plt.scatter(fprs, tprs, [], \"ROC curve\", \"points\", 0, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:44:00.779645Z",
     "start_time": "2020-11-30T18:44:00.776156Z"
    }
   },
   "outputs": [],
   "source": [
    "rfclf = RandomForestClassifier(n_estimators=400, criterion='entropy', n_jobs=-1, min_samples_leaf=3, warm_start=True, verbose=0)\n",
    "etclf = ExtraTreesClassifier(n_estimators=400, n_jobs=-1,min_samples_leaf=3, warm_start=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:44:02.383716Z",
     "start_time": "2020-11-30T18:44:02.378315Z"
    }
   },
   "outputs": [],
   "source": [
    "vcclf = VotingClassifier(estimators=[('rf', rfclf), ('et', etclf)], voting='soft', weights=[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e validando o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:44:29.894265Z",
     "start_time": "2020-11-30T18:44:07.017710Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Fitting:\n",
      "==> Extra Trees\n",
      "Random Forest\n",
      "Voting\n",
      "==> Scoring:\n",
      "==> Fitting:\n",
      "==> Extra Trees\n",
      "Random Forest\n",
      "Voting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Scoring:\n",
      "==> Fitting:\n",
      "==> Extra Trees\n",
      "Random Forest\n",
      "Voting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py:368: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Scoring:\n",
      "\n",
      "Classification Report for ET:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       0.00      0.00      0.00       249\n",
      "  Biográfico       0.48      1.00      0.65       233\n",
      "\n",
      "    accuracy                           0.48       482\n",
      "   macro avg       0.24      0.50      0.33       482\n",
      "weighted avg       0.23      0.48      0.32       482\n",
      "\n",
      "\n",
      "Classification Report for RF:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       0.00      0.00      0.00       249\n",
      "  Biográfico       0.48      1.00      0.65       233\n",
      "\n",
      "    accuracy                           0.48       482\n",
      "   macro avg       0.24      0.50      0.33       482\n",
      "weighted avg       0.23      0.48      0.32       482\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Voting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       0.00      0.00      0.00       249\n",
      "  Biográfico       0.48      1.00      0.65       233\n",
      "\n",
      "    accuracy                           0.48       482\n",
      "   macro avg       0.24      0.50      0.33       482\n",
      "weighted avg       0.23      0.48      0.32       482\n",
      "\n",
      "RF: AUCs: [0.999822695035461, 1.0, 1.0]\n",
      "[0.00567857 0.99432143] (2,)\n",
      "[9.375000e-04 9.990625e-01] (2,)\n",
      "[0.06672768 0.93327232] (2,)\n",
      "Voting: AUCs: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "s must be a scalar, or the same size as x and y",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c14de4b3b7d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     plot_learning(acc_hist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mplot_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# print('trained {} documents.'.format((n+1)*batchsize))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-14b6fac21cad>\u001b[0m in \u001b[0;36mplot_roc\u001b[0;34m(probas)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}: AUCs: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_aucs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfprs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtprs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ROC curve\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"points\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2888\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m         edgecolors=None, *, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 2890\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   2891\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 **kwargs)\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4446\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4448\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s must be a scalar, or the same size as x and y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4450\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: s must be a scalar, or the same size as x and y"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "scaler = StandardScaler()\n",
    "\n",
    "acc_hist = defaultdict(lambda: [])\n",
    "\n",
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(data2.values,Y2, test_size=.25)\n",
    "\n",
    "probas = defaultdict(lambda: [])\n",
    "skf = StratifiedKFold(3, shuffle=True)\n",
    "\n",
    "for train_index, test_index in skf.split(Xtrain, Ytrain):\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    print(\"==> Fitting:\")\n",
    "    print(\"==> Extra Trees\")\n",
    "    etclf.fit(X[train_index],Y[train_index])\n",
    "    print(\"Random Forest\")\n",
    "    rfclf.fit(X[train_index], Y[train_index])\n",
    "    probas['RF'].append((rfclf.predict_proba(X[test_index]), Y[test_index]))\n",
    "    print(\"Voting\")\n",
    "    vcclf.fit(X[train_index], Y[train_index])\n",
    "    probas['Voting'].append(vcclf.predict_proba(X[test_index]))\n",
    "    print(\"==> Scoring:\")\n",
    "    acc_hist['ET'].append(cross_val_score(etclf, X[test_index], Y[test_index], cv=2, n_jobs=-1).mean())\n",
    "\n",
    "    acc_hist['RF'].append(cross_val_score(rfclf, X[test_index], Y[test_index], cv=2, n_jobs=-1).mean())\n",
    "    acc_hist['Voting'].append(vcclf.score(X[test_index], Y[test_index]))\n",
    "print_class_report(Xtest, Ytest, etclf, 'ET')\n",
    "print_class_report(Xtest, Ytest, rfclf, 'RF')\n",
    "print_class_report(Xtest, Ytest, vcclf, 'Voting')\n",
    "\n",
    "#     plot_learning(acc_hist)\n",
    "plot_roc(probas)\n",
    "\n",
    "# print('trained {} documents.'.format((n+1)*batchsize))\n",
    "df_acc = pd.DataFrame(acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:34:46.459934Z",
     "start_time": "2020-11-30T18:34:46.451084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5765, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:34:47.200538Z",
     "start_time": "2020-11-30T18:34:47.195068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5765,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 350,
   "position": {
    "height": "40px",
    "left": "651px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
