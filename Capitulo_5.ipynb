{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo um Classificador de Textos\n",
    "Uma das aplicações mais comuns em mineração de textos é a classificações de documentos em categorias pré-definidas, sejam elas autorais, temáticas, temporais ou outras. \n",
    "\n",
    "Neste capítulo iremos explorar os passos necessários para o desenvolvimento de um classificador de documentos utilizando as análises feitas sobre o corpus do DHBB nos capítulos anteriores.\n",
    "\n",
    "Para esta tarefa utilizaremos modelos de machine learning clássicos disponibilizados na biblioteca [Scikit-Learn](https://scikit-learn.org/). Começaremos então importando algumas funcionalidades a partir do Scikit-Learn. Os demais imports já foram utilizados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:20:06.928139Z",
     "start_time": "2019-11-25T18:20:06.906408Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from gensim.models import Word2Vec, word2vec\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from string import punctuation\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o corpus\n",
    "Vamos utilizar o corpus do DHBB conforme armazenado na biblioteca SQLite anteriormente. Abaixo iremos desenvolver um iterador sobre o corpus que fará um preprocessamento básico dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:52:01.897384Z",
     "start_time": "2019-11-25T18:52:01.700449Z"
    }
   },
   "outputs": [],
   "source": [
    "eng = create_engine(\"sqlite:///minha_tabela.sqlite\")\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "class DHBBCorpus:\n",
    "    def __init__(self, ndocs=10000):\n",
    "        self.ndocs = min(7687,ndocs)\n",
    "        self.counter = 1\n",
    "    def __iter__(self):\n",
    "        with eng.connect() as con:\n",
    "            res = con.execute(f'select corpo from resultados limit {self.ndocs};')\n",
    "            for doc in res:\n",
    "                d = self.pre_process(doc[0])\n",
    "                if self.counter%10 == 0:\n",
    "                    print (f\"Verbete {self.counter} de {self.ndocs}\\r\", end='')\n",
    "                \n",
    "                yield d\n",
    "                self.counter += 1\n",
    "    def pre_process(self, doc):\n",
    "        n = nlp(doc, disable=['tagger', 'ner','entity-linker', 'textcat','entity-ruler','merge-noun-chunks','merge-entities','merge-subtokens'])\n",
    "        results = [token.text.strip().strip(punctuation) for token in n if not token.is_stop]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Modelo Word2vec\n",
    "Vamos utilizar a representação vetorial do corpus construida anteriormente como base para o treinamento do classificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T17:51:04.715253Z",
     "start_time": "2019-11-25T17:51:04.313931Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('dhbb.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:52:14.629033Z",
     "start_time": "2019-11-25T18:52:14.624850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38762, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como  o word2vec é uma representação vetorial do vocabulário do corpus, e desejamos treinar um modelo para classificar documentos, precisamos primeiro construir uma representação dos documentos do corpus no mesmo espaço vetorial gerado pelo Word2vec.\n",
    "\n",
    "Na função abaixo, contruimos um vetor de documento que é a média dos vetores das palavras únicas que este contém."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:19:32.224302Z",
     "start_time": "2019-11-25T18:19:32.211929Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def build_document_vector(text):\n",
    "    \"\"\"\n",
    "    Build a scaled vector for the document (mean of the words present in it)\n",
    "    :param text: document to be vectorized (tokenized)\n",
    "    :param model: word2vec model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    feature_count = model.wv.vectors.shape[1]\n",
    "    vec = np.zeros(feature_count).reshape((1, feature_count))\n",
    "    count = 0.\n",
    "    \n",
    "\n",
    "    for word in text:\n",
    "        try:\n",
    "            vec += model.wv[word].reshape((1, feature_count))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T18:55:16.882377Z",
     "start_time": "2019-11-25T18:55:16.879628Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def gera_docv(n):\n",
    "    corpus = DHBBCorpus(n)\n",
    "    for doc in corpus:\n",
    "        v = build_document_vector(set(doc))\n",
    "        yield v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados treinamento do Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T19:09:40.103431Z",
     "start_time": "2019-11-25T18:58:41.252380Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbete 7680 de 7687\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.296355</td>\n",
       "      <td>-0.369351</td>\n",
       "      <td>-0.219112</td>\n",
       "      <td>-0.011535</td>\n",
       "      <td>-0.356944</td>\n",
       "      <td>0.057425</td>\n",
       "      <td>0.636584</td>\n",
       "      <td>-0.031091</td>\n",
       "      <td>-0.371255</td>\n",
       "      <td>0.106736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075344</td>\n",
       "      <td>-0.159404</td>\n",
       "      <td>-0.233228</td>\n",
       "      <td>0.010510</td>\n",
       "      <td>0.757997</td>\n",
       "      <td>0.168332</td>\n",
       "      <td>0.209847</td>\n",
       "      <td>-0.646779</td>\n",
       "      <td>-0.494476</td>\n",
       "      <td>0.050851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.047746</td>\n",
       "      <td>-0.046702</td>\n",
       "      <td>-0.190949</td>\n",
       "      <td>0.577955</td>\n",
       "      <td>0.155968</td>\n",
       "      <td>0.225539</td>\n",
       "      <td>0.211839</td>\n",
       "      <td>-0.107882</td>\n",
       "      <td>-0.071698</td>\n",
       "      <td>0.108209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343698</td>\n",
       "      <td>0.062024</td>\n",
       "      <td>-0.120656</td>\n",
       "      <td>0.116875</td>\n",
       "      <td>0.259419</td>\n",
       "      <td>0.288715</td>\n",
       "      <td>0.168819</td>\n",
       "      <td>-0.298981</td>\n",
       "      <td>-0.517028</td>\n",
       "      <td>0.308318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191656</td>\n",
       "      <td>-0.186713</td>\n",
       "      <td>-0.269119</td>\n",
       "      <td>0.111749</td>\n",
       "      <td>-0.207819</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.069423</td>\n",
       "      <td>-0.323620</td>\n",
       "      <td>-0.119195</td>\n",
       "      <td>-0.002357</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190077</td>\n",
       "      <td>0.420614</td>\n",
       "      <td>-0.118308</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.213823</td>\n",
       "      <td>0.026442</td>\n",
       "      <td>-0.033372</td>\n",
       "      <td>-0.273386</td>\n",
       "      <td>0.125667</td>\n",
       "      <td>0.066307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>-0.059873</td>\n",
       "      <td>-0.280428</td>\n",
       "      <td>0.378681</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.141234</td>\n",
       "      <td>0.169813</td>\n",
       "      <td>-0.022787</td>\n",
       "      <td>-0.217140</td>\n",
       "      <td>0.172066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196561</td>\n",
       "      <td>0.124252</td>\n",
       "      <td>0.025444</td>\n",
       "      <td>0.031496</td>\n",
       "      <td>-0.001780</td>\n",
       "      <td>0.221582</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>-0.161416</td>\n",
       "      <td>-0.288433</td>\n",
       "      <td>0.343550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033655</td>\n",
       "      <td>-0.257470</td>\n",
       "      <td>-0.435646</td>\n",
       "      <td>0.096290</td>\n",
       "      <td>-0.507049</td>\n",
       "      <td>-0.220573</td>\n",
       "      <td>0.253772</td>\n",
       "      <td>0.591106</td>\n",
       "      <td>-0.738819</td>\n",
       "      <td>0.498734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>-0.008746</td>\n",
       "      <td>-0.341211</td>\n",
       "      <td>-0.454881</td>\n",
       "      <td>1.328264</td>\n",
       "      <td>0.269425</td>\n",
       "      <td>0.735788</td>\n",
       "      <td>-0.424710</td>\n",
       "      <td>-0.949855</td>\n",
       "      <td>0.047187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7682</td>\n",
       "      <td>-0.097823</td>\n",
       "      <td>-0.078286</td>\n",
       "      <td>-0.375540</td>\n",
       "      <td>0.583358</td>\n",
       "      <td>-0.058045</td>\n",
       "      <td>0.269644</td>\n",
       "      <td>0.320550</td>\n",
       "      <td>-0.223646</td>\n",
       "      <td>-0.040692</td>\n",
       "      <td>-0.032362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273379</td>\n",
       "      <td>0.021381</td>\n",
       "      <td>-0.304205</td>\n",
       "      <td>0.141669</td>\n",
       "      <td>0.163567</td>\n",
       "      <td>0.197348</td>\n",
       "      <td>0.046773</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.608374</td>\n",
       "      <td>0.099034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7683</td>\n",
       "      <td>0.179406</td>\n",
       "      <td>-0.121504</td>\n",
       "      <td>-0.562740</td>\n",
       "      <td>0.047880</td>\n",
       "      <td>-0.832265</td>\n",
       "      <td>-0.569388</td>\n",
       "      <td>0.306019</td>\n",
       "      <td>0.671887</td>\n",
       "      <td>-0.339240</td>\n",
       "      <td>0.517512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486355</td>\n",
       "      <td>-0.092336</td>\n",
       "      <td>-0.464590</td>\n",
       "      <td>-0.744464</td>\n",
       "      <td>1.226775</td>\n",
       "      <td>0.115940</td>\n",
       "      <td>0.150833</td>\n",
       "      <td>-0.272562</td>\n",
       "      <td>-0.524888</td>\n",
       "      <td>-0.228353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7684</td>\n",
       "      <td>-0.303439</td>\n",
       "      <td>-0.413298</td>\n",
       "      <td>-0.492052</td>\n",
       "      <td>0.071817</td>\n",
       "      <td>-0.198558</td>\n",
       "      <td>0.158098</td>\n",
       "      <td>0.492865</td>\n",
       "      <td>0.041102</td>\n",
       "      <td>-0.143934</td>\n",
       "      <td>0.048369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009319</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>-0.335632</td>\n",
       "      <td>-0.023029</td>\n",
       "      <td>0.161608</td>\n",
       "      <td>0.404850</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>-0.387414</td>\n",
       "      <td>-0.421911</td>\n",
       "      <td>0.199390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7685</td>\n",
       "      <td>0.115561</td>\n",
       "      <td>-0.189773</td>\n",
       "      <td>-0.054918</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>-0.266947</td>\n",
       "      <td>0.112972</td>\n",
       "      <td>0.494245</td>\n",
       "      <td>-0.106279</td>\n",
       "      <td>-0.168027</td>\n",
       "      <td>0.263188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033749</td>\n",
       "      <td>-0.103522</td>\n",
       "      <td>-0.494310</td>\n",
       "      <td>-0.084172</td>\n",
       "      <td>0.415913</td>\n",
       "      <td>0.078416</td>\n",
       "      <td>0.180037</td>\n",
       "      <td>-0.411079</td>\n",
       "      <td>-0.181538</td>\n",
       "      <td>0.041477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7686</td>\n",
       "      <td>0.121273</td>\n",
       "      <td>-0.067814</td>\n",
       "      <td>-0.210392</td>\n",
       "      <td>0.323656</td>\n",
       "      <td>0.038728</td>\n",
       "      <td>0.247873</td>\n",
       "      <td>0.051775</td>\n",
       "      <td>-0.093789</td>\n",
       "      <td>-0.143175</td>\n",
       "      <td>0.180506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137562</td>\n",
       "      <td>0.384644</td>\n",
       "      <td>0.041556</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.088625</td>\n",
       "      <td>0.126252</td>\n",
       "      <td>-0.032567</td>\n",
       "      <td>-0.139912</td>\n",
       "      <td>-0.110532</td>\n",
       "      <td>0.248373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7687 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.296355 -0.369351 -0.219112 -0.011535 -0.356944  0.057425  0.636584   \n",
       "1    -0.047746 -0.046702 -0.190949  0.577955  0.155968  0.225539  0.211839   \n",
       "2     0.191656 -0.186713 -0.269119  0.111749 -0.207819  0.006255  0.069423   \n",
       "3     0.003558 -0.059873 -0.280428  0.378681  0.008146  0.141234  0.169813   \n",
       "4     0.033655 -0.257470 -0.435646  0.096290 -0.507049 -0.220573  0.253772   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7682 -0.097823 -0.078286 -0.375540  0.583358 -0.058045  0.269644  0.320550   \n",
       "7683  0.179406 -0.121504 -0.562740  0.047880 -0.832265 -0.569388  0.306019   \n",
       "7684 -0.303439 -0.413298 -0.492052  0.071817 -0.198558  0.158098  0.492865   \n",
       "7685  0.115561 -0.189773 -0.054918 -0.000709 -0.266947  0.112972  0.494245   \n",
       "7686  0.121273 -0.067814 -0.210392  0.323656  0.038728  0.247873  0.051775   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0    -0.031091 -0.371255  0.106736  ... -0.075344 -0.159404 -0.233228   \n",
       "1    -0.107882 -0.071698  0.108209  ...  0.343698  0.062024 -0.120656   \n",
       "2    -0.323620 -0.119195 -0.002357  ... -0.190077  0.420614 -0.118308   \n",
       "3    -0.022787 -0.217140  0.172066  ...  0.196561  0.124252  0.025444   \n",
       "4     0.591106 -0.738819  0.498734  ...  0.052100 -0.008746 -0.341211   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7682 -0.223646 -0.040692 -0.032362  ...  0.273379  0.021381 -0.304205   \n",
       "7683  0.671887 -0.339240  0.517512  ... -0.486355 -0.092336 -0.464590   \n",
       "7684  0.041102 -0.143934  0.048369  ... -0.009319 -0.001092 -0.335632   \n",
       "7685 -0.106279 -0.168027  0.263188  ... -0.033749 -0.103522 -0.494310   \n",
       "7686 -0.093789 -0.143175  0.180506  ...  0.137562  0.384644  0.041556   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0     0.010510  0.757997  0.168332  0.209847 -0.646779 -0.494476  0.050851  \n",
       "1     0.116875  0.259419  0.288715  0.168819 -0.298981 -0.517028  0.308318  \n",
       "2     0.006932  0.213823  0.026442 -0.033372 -0.273386  0.125667  0.066307  \n",
       "3     0.031496 -0.001780  0.221582  0.003191 -0.161416 -0.288433  0.343550  \n",
       "4    -0.454881  1.328264  0.269425  0.735788 -0.424710 -0.949855  0.047187  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7682  0.141669  0.163567  0.197348  0.046773 -0.304688 -0.608374  0.099034  \n",
       "7683 -0.744464  1.226775  0.115940  0.150833 -0.272562 -0.524888 -0.228353  \n",
       "7684 -0.023029  0.161608  0.404850  0.005394 -0.387414 -0.421911  0.199390  \n",
       "7685 -0.084172  0.415913  0.078416  0.180037 -0.411079 -0.181538  0.041477  \n",
       "7686  0.016529  0.088625  0.126252 -0.032567 -0.139912 -0.110532  0.248373  \n",
       "\n",
       "[7687 rows x 100 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerador = gera_docv(10000)\n",
    "data = pd.DataFrame(data=np.vstack([a for a in gerador]), columns=range(100))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a categoria de cada documento para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T19:13:21.597956Z",
     "start_time": "2019-11-25T19:13:21.439136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7687"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gera_alvo():\n",
    "    df = pd.read_sql_query('select * from resultados', con=eng)\n",
    "    alvo = df.natureza.values=='biográfico'\n",
    "    return alvo\n",
    "Y = gera_alvo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T19:41:11.795565Z",
     "start_time": "2019-11-25T19:41:11.775655Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_class_report(Xtest, Ytest, clf, clf_name):\n",
    "    \"\"\"\n",
    "    Prints Classification report\n",
    "    :param Xtest:\n",
    "    :param Ytest:\n",
    "    :param clf: trained classifier\n",
    "    :param clf_name: Name for the classifier\n",
    "    \"\"\"\n",
    "    y_predict = clf.predict(Xtest)\n",
    "    print('\\nClassification Report for {}:\\n'.format(clf_name))\n",
    "    print(classification_report(Ytest, y_predict, target_names=['Temático', 'Biográfico']))\n",
    "    \n",
    "\n",
    "def plot_roc(probas):\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "\n",
    "\n",
    "    labels = ['False positive rate', 'True Positive rate']\n",
    "    for k, v in probas.items():\n",
    "        roc_aucs = []\n",
    "        for j, fold in enumerate(v):\n",
    "            try:\n",
    "                fpr, tpr, thresholds = roc_curve(fold[1], fold[0][:, 1])\n",
    "            except IndexError:\n",
    "                print(fold[0], fold[0].shape)\n",
    "                continue\n",
    "            roc_aucs.append(auc(fpr, tpr))\n",
    "            tprs.append([float(t) for t in tpr])\n",
    "            fprs.append([float(f) for f in fpr])\n",
    "\n",
    "        print('{}: AUCs: {}'.format(k, str(roc_aucs)))\n",
    "    # pserver2.scatter(fprs, tprs, [], \"ROC curve\", \"points\", 0, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T19:41:15.386439Z",
     "start_time": "2019-11-25T19:41:15.383249Z"
    }
   },
   "outputs": [],
   "source": [
    "rfclf = RandomForestClassifier(n_estimators=400, criterion='entropy', n_jobs=-1, min_samples_leaf=3, warm_start=True, verbose=0)\n",
    "etclf = ExtraTreesClassifier(n_estimators=400, n_jobs=-1,min_samples_leaf=3, warm_start=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T19:41:15.760273Z",
     "start_time": "2019-11-25T19:41:15.744526Z"
    }
   },
   "outputs": [],
   "source": [
    "vcclf = VotingClassifier(estimators=[('rf', rfclf), ('et', etclf)], voting='soft', weights=[2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e validando o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T19:41:40.001021Z",
     "start_time": "2019-11-25T19:41:17.130326Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Fitting:\n",
      "==> Extra Trees\n",
      "Random Forest\n",
      "Voting\n",
      "==> Scoring:\n",
      "\n",
      "Classification Report for ET:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       0.97      0.95      0.96       482\n",
      "  Biográfico       0.99      1.00      0.99      3362\n",
      "\n",
      "    accuracy                           0.99      3844\n",
      "   macro avg       0.98      0.97      0.98      3844\n",
      "weighted avg       0.99      0.99      0.99      3844\n",
      "\n",
      "\n",
      "Classification Report for RF:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       0.96      0.96      0.96       482\n",
      "  Biográfico       0.99      0.99      0.99      3362\n",
      "\n",
      "    accuracy                           0.99      3844\n",
      "   macro avg       0.98      0.98      0.98      3844\n",
      "weighted avg       0.99      0.99      0.99      3844\n",
      "\n",
      "\n",
      "Classification Report for Voting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       0.97      0.95      0.96       482\n",
      "  Biográfico       0.99      1.00      0.99      3362\n",
      "\n",
      "    accuracy                           0.99      3844\n",
      "   macro avg       0.98      0.97      0.98      3844\n",
      "weighted avg       0.99      0.99      0.99      3844\n",
      "\n",
      "==> Fitting:\n",
      "==> Extra Trees\n",
      "Random Forest\n",
      "Voting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Scoring:\n",
      "\n",
      "Classification Report for ET:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       1.00      1.00      1.00       481\n",
      "  Biográfico       1.00      1.00      1.00      3362\n",
      "\n",
      "    accuracy                           1.00      3843\n",
      "   macro avg       1.00      1.00      1.00      3843\n",
      "weighted avg       1.00      1.00      1.00      3843\n",
      "\n",
      "\n",
      "Classification Report for RF:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       1.00      1.00      1.00       481\n",
      "  Biográfico       1.00      1.00      1.00      3362\n",
      "\n",
      "    accuracy                           1.00      3843\n",
      "   macro avg       1.00      1.00      1.00      3843\n",
      "weighted avg       1.00      1.00      1.00      3843\n",
      "\n",
      "\n",
      "Classification Report for Voting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Temático       0.96      0.89      0.92       481\n",
      "  Biográfico       0.98      0.99      0.99      3362\n",
      "\n",
      "    accuracy                           0.98      3843\n",
      "   macro avg       0.97      0.94      0.96      3843\n",
      "weighted avg       0.98      0.98      0.98      3843\n",
      "\n",
      "RF: AUCs: [0.9986806410924144, 0.9999987632349322]\n",
      "[0.00456944 0.99543056] (2,)\n",
      "[6.52777778e-04 9.99347222e-01] (2,)\n",
      "Voting: AUCs: []\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "scaler = StandardScaler()\n",
    "\n",
    "acc_hist = defaultdict(lambda: [])\n",
    "\n",
    "X = data.as_matrix()\n",
    "probas = defaultdict(lambda: [])\n",
    "skf = StratifiedKFold(2, shuffle=True)\n",
    "\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    print(\"==> Fitting:\")\n",
    "    print(\"==> Extra Trees\")\n",
    "    etclf.fit(X[train_index],Y[train_index])\n",
    "    print(\"Random Forest\")\n",
    "    rfclf.fit(X[train_index], Y[train_index])\n",
    "    probas['RF'].append((rfclf.predict_proba(X[test_index]), Y[test_index]))\n",
    "    print(\"Voting\")\n",
    "    vcclf.fit(X[train_index], Y[train_index])\n",
    "    probas['Voting'].append(vcclf.predict_proba(X[test_index]))\n",
    "    print(\"==> Scoring:\")\n",
    "    acc_hist['ET'].append(cross_val_score(etclf, X[test_index], Y[test_index], cv=2, n_jobs=-1).mean())\n",
    "\n",
    "    acc_hist['RF'].append(cross_val_score(rfclf, X[test_index], Y[test_index], cv=2, n_jobs=-1).mean())\n",
    "    acc_hist['Voting'].append(vcclf.score(X[test_index], Y[test_index]))\n",
    "    print_class_report(X[test_index], Y[test_index], etclf, 'ET')\n",
    "    print_class_report(X[test_index], Y[test_index], rfclf, 'RF')\n",
    "    print_class_report(X[test_index], Y[test_index], vcclf, 'Voting')\n",
    "\n",
    "#     plot_learning(acc_hist)\n",
    "plot_roc(probas)\n",
    "\n",
    "# print('trained {} documents.'.format((n+1)*batchsize))\n",
    "df_acc = pd.DataFrame(acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 350,
   "position": {
    "height": "40px",
    "left": "651px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
