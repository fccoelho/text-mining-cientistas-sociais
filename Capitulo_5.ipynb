{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo um Classificador de Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_document_vector(text):\n",
    "    \"\"\"\n",
    "    Build a scaled vector for the document (mean of the words present in it)\n",
    "    :param text: document to be vectorized (tokenized)\n",
    "    :param model: word2vec model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    vocab = set([])\n",
    "    feature_count = model.syn0.shape[1]\n",
    "    vec = np.zeros(feature_count).reshape((1, feature_count))\n",
    "    count = 0.\n",
    "    frases = [bigram[f] for f in _get_phrases(text)]\n",
    "\n",
    "    for f in frases:\n",
    "        for word in f:\n",
    "            if word in vocab:\n",
    "                continue\n",
    "            try:\n",
    "                vec += model[word].reshape((1, feature_count))\n",
    "                vocab.add(word)\n",
    "                count += 1.\n",
    "            except KeyError:\n",
    "                continue\n",
    "        if count != 0:\n",
    "            vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_docvec(fname, chunk):\n",
    "    reader = pd.read_csv(fname, chunksize=chunk)\n",
    "    for df in reader:\n",
    "        yield df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclf = RandomForestClassifier(n_estimators=400, criterion='entropy', n_jobs=-1, min_samples_leaf=3, warm_start=True, verbose=0)\n",
    "etclf = ExtraTreesClassifier(n_estimators=400, n_jobs=-1,min_samples_leaf=3, warm_start=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcclf = VotingClassifier(estimators=[('rf', rfclf), ('et', etclf)], voting='soft', weights=[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstreamer = stream_docvec('docvs.csv', batchsize)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    acc_hist = defaultdict(lambda: [])\n",
    "    for n, df in enumerate(docstreamer):\n",
    "        try:\n",
    "            Y = get_Y(get_original_class(df['ids']))\n",
    "        except Exception as e:\n",
    "            raise(e)\n",
    "            break\n",
    "        X = df.as_matrix()[:, :-2]  # remove ids and labels columns at the end\n",
    "        probas = defaultdict(lambda: [])\n",
    "        skf = StratifiedKFold(2, shuffle=True)\n",
    "        print(df.ids.head(),Y)\n",
    "        for train_index, test_index in skf.split(X, Y):\n",
    "            scaler.fit(X)\n",
    "            X = scaler.transform(X)\n",
    "            print(\"==> Fitting:\")\n",
    "            # print (\"Passive Agressive\")\n",
    "            # paclf.partial_fit(X[train_index], Y[train_index], classes=np.array([0, 1]))\n",
    "            # probas['pa'].append((paclf.predict_proba(X[test_index]), Y[test_index]))\n",
    "            print (\"SGDC\")\n",
    "            sgclf.partial_fit(X[train_index], Y[train_index], classes=np.array([0, 1]))\n",
    "            probas['SGDC'].append((sgclf.predict_proba(X[test_index]), Y[test_index]))\n",
    "            print(\"Random Forest\")\n",
    "            rfclf.fit(X[train_index], Y[train_index])\n",
    "            probas['RF'].append((rfclf.predict_proba(X[test_index]), Y[test_index]))\n",
    "            print(\"Voting\")\n",
    "            vcclf.fit(X[train_index], Y[train_index])\n",
    "            probas['Voting'].append(vcclf.predict_proba(X[test_index]))\n",
    "            print(\"==> Scoring:\")\n",
    "            # acc_hist['pa'].append(cross_val_score(paclf, X[test_index], Y[test_index], cv=2, n_jobs=-1).mean())\n",
    "            acc_hist['SGD'].append(cross_val_score(sgclf, X[test_index], Y[test_index], cv=2, n_jobs=-1).mean())\n",
    "            acc_hist['RF'].append(cross_val_score(rfclf, X[test_index], Y[test_index], cv=2, n_jobs=-1).mean())\n",
    "            acc_hist['Voting'].append(vcclf.score(X[test_index], Y[test_index]))\n",
    "            print_class_report(X[test_index], Y[test_index], sgclf, 'SGDC')\n",
    "            print_class_report(X[test_index], Y[test_index], rfclf, 'RF')\n",
    "            print_class_report(X[test_index], Y[test_index], vcclf, 'Voting')\n",
    "\n",
    "            plot_learning(acc_hist)\n",
    "        plot_roc(probas)\n",
    "\n",
    "        print('trained {} documents.'.format((n+1)*batchsize))\n",
    "    df_acc = pd.DataFrame(acc_hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
