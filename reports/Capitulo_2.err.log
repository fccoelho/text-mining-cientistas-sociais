Traceback (most recent call last):
  File "/home/fccoelho/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/home/fccoelho/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nbclient/client.py", line 1305, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/fccoelho/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/fccoelho/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nbclient/client.py", line 705, in async_execute
    await self.async_execute_cell(
  File "/home/fccoelho/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nbclient/client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/fccoelho/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nbclient/client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
palavras = nltk.word_tokenize(biograficos.corpo[0])
palavras[:10]
------------------


[31m---------------------------------------------------------------------------[39m
[31mLookupError[39m                               Traceback (most recent call last)
[36mCell[39m[36m [39m[32mIn[8][39m[32m, line 1[39m
[32m----> [39m[32m1[39m palavras = [43mnltk[49m[43m.[49m[43mword_tokenize[49m[43m([49m[43mbiograficos[49m[43m.[49m[43mcorpo[49m[43m[[49m[32;43m0[39;49m[43m][49m[43m)[49m
[32m      2[39m palavras[:[32m10[39m]

[36mFile [39m[32m~/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py:142[39m, in [36mword_tokenize[39m[34m(text, language, preserve_line)[39m
[32m    127[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34mword_tokenize[39m(text, language=[33m"[39m[33menglish[39m[33m"[39m, preserve_line=[38;5;28;01mFalse[39;00m):
[32m    128[39m [38;5;250m    [39m[33;03m"""[39;00m
[32m    129[39m [33;03m    Return a tokenized copy of *text*,[39;00m
[32m    130[39m [33;03m    using NLTK's recommended word tokenizer[39;00m
[32m   (...)[39m[32m    140[39m [33;03m    :type preserve_line: bool[39;00m
[32m    141[39m [33;03m    """[39;00m
[32m--> [39m[32m142[39m     sentences = [text] [38;5;28;01mif[39;00m preserve_line [38;5;28;01melse[39;00m [43msent_tokenize[49m[43m([49m[43mtext[49m[43m,[49m[43m [49m[43mlanguage[49m[43m)[49m
[32m    143[39m     [38;5;28;01mreturn[39;00m [
[32m    144[39m         token [38;5;28;01mfor[39;00m sent [38;5;129;01min[39;00m sentences [38;5;28;01mfor[39;00m token [38;5;129;01min[39;00m _treebank_word_tokenizer.tokenize(sent)
[32m    145[39m     ]

[36mFile [39m[32m~/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py:119[39m, in [36msent_tokenize[39m[34m(text, language)[39m
[32m    109[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34msent_tokenize[39m(text, language=[33m"[39m[33menglish[39m[33m"[39m):
[32m    110[39m [38;5;250m    [39m[33;03m"""[39;00m
[32m    111[39m [33;03m    Return a sentence-tokenized copy of *text*,[39;00m
[32m    112[39m [33;03m    using NLTK's recommended sentence tokenizer[39;00m
[32m   (...)[39m[32m    117[39m [33;03m    :param language: the model name in the Punkt corpus[39;00m
[32m    118[39m [33;03m    """[39;00m
[32m--> [39m[32m119[39m     tokenizer = [43m_get_punkt_tokenizer[49m[43m([49m[43mlanguage[49m[43m)[49m
[32m    120[39m     [38;5;28;01mreturn[39;00m tokenizer.tokenize(text)

[36mFile [39m[32m~/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py:105[39m, in [36m_get_punkt_tokenizer[39m[34m(language)[39m
[32m     96[39m [38;5;129m@functools[39m.lru_cache
[32m     97[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34m_get_punkt_tokenizer[39m(language=[33m"[39m[33menglish[39m[33m"[39m):
[32m     98[39m [38;5;250m    [39m[33;03m"""[39;00m
[32m     99[39m [33;03m    A constructor for the PunktTokenizer that utilizes[39;00m
[32m    100[39m [33;03m    a lru cache for performance.[39;00m
[32m   (...)[39m[32m    103[39m [33;03m    :type language: str[39;00m
[32m    104[39m [33;03m    """[39;00m
[32m--> [39m[32m105[39m     [38;5;28;01mreturn[39;00m [43mPunktTokenizer[49m[43m([49m[43mlanguage[49m[43m)[49m

[36mFile [39m[32m~/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1744[39m, in [36mPunktTokenizer.__init__[39m[34m(self, lang)[39m
[32m   1742[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34m__init__[39m([38;5;28mself[39m, lang=[33m"[39m[33menglish[39m[33m"[39m):
[32m   1743[39m     PunktSentenceTokenizer.[34m__init__[39m([38;5;28mself[39m)
[32m-> [39m[32m1744[39m     [38;5;28;43mself[39;49m[43m.[49m[43mload_lang[49m[43m([49m[43mlang[49m[43m)[49m

[36mFile [39m[32m~/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1749[39m, in [36mPunktTokenizer.load_lang[39m[34m(self, lang)[39m
[32m   1746[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34mload_lang[39m([38;5;28mself[39m, lang=[33m"[39m[33menglish[39m[33m"[39m):
[32m   1747[39m     [38;5;28;01mfrom[39;00m[38;5;250m [39m[34;01mnltk[39;00m[34;01m.[39;00m[34;01mdata[39;00m[38;5;250m [39m[38;5;28;01mimport[39;00m find
[32m-> [39m[32m1749[39m     lang_dir = [43mfind[49m[43m([49m[33;43mf[39;49m[33;43m"[39;49m[33;43mtokenizers/punkt_tab/[39;49m[38;5;132;43;01m{[39;49;00m[43mlang[49m[38;5;132;43;01m}[39;49;00m[33;43m/[39;49m[33;43m"[39;49m[43m)[49m
[32m   1750[39m     [38;5;28mself[39m._params = load_punkt_params(lang_dir)
[32m   1751[39m     [38;5;28mself[39m._lang = lang

[36mFile [39m[32m~/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/python3.12/site-packages/nltk/data.py:579[39m, in [36mfind[39m[34m(resource_name, paths)[39m
[32m    577[39m sep = [33m"[39m[33m*[39m[33m"[39m * [32m70[39m
[32m    578[39m resource_not_found = [33mf[39m[33m"[39m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00msep[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00mmsg[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00msep[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[33m"[39m
[32m--> [39m[32m579[39m [38;5;28;01mraise[39;00m [38;5;167;01mLookupError[39;00m(resource_not_found)

[31mLookupError[39m: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/home/fccoelho/nltk_data'
    - '/home/fccoelho/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/nltk_data'
    - '/home/fccoelho/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/share/nltk_data'
    - '/home/fccoelho/Documentos/Projects_software/text-mining-cientistas-sociais/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************


